import os
import re
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.tools import Tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.tools.tavily_search import TavilySearchResults
from typing import List, Dict

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
embeddings = OpenAIEmbeddings()
text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)

# 1. PDF ë¬¸ì„œ ë¡œë”© ë° metadata ì‚½ì…
def load_docs_with_metadata(path: str, crop: str) -> List:
    docs = PDFPlumberLoader(path).load()
    for i, doc in enumerate(docs):
        doc.metadata["ì‘ë¬¼"] = crop
        doc.metadata["ì¶œì²˜"] = os.path.basename(path)
        doc.metadata["í˜ì´ì§€"] = i

        # ë³‘í•´ì¶©ëª… ì¶”ì¶œ: ì˜ˆ) 1. íƒ„ì €ë³‘
        match = re.search(r"\d+\.\s*([ê°€-í£]+ë³‘|ì‘ì• |ì§„ë”§ë¬¼)", doc.page_content)
        if match:
            doc.metadata["ë³‘í•´ì¶©ëª…"] = match.group(1)
    return docs

# 2. ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•„í„° ì¡°ê±´ ì¶”ì¶œ
def extract_filter_from_query(query: str) -> Dict:
    crop_match = re.search(r"(ë”¸ê¸°|í† ë§ˆí† )", query)
    pest_match = re.search(r"([ê°€-í£]+ë³‘|ì‘ì• |ì§„ë”§ë¬¼)", query)

    filter_dict = {}
    if crop_match:
        filter_dict["ì‘ë¬¼"] = crop_match.group(1)
    if pest_match:
        filter_dict["ë³‘í•´ì¶©ëª…"] = pest_match.group(1)
    return filter_dict

# 3. ì›¹ ê²€ìƒ‰ íˆ´
def web_search_with_notice(query: str) -> str:
    results = TavilySearchResults().invoke(query)
    return str(results) + "\n\nğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œê³µëœ ì •ë³´ì…ë‹ˆë‹¤."

web_search_tool = Tool(
    name="web_search_tool",
    func=web_search_with_notice,
    description=(
        "ë”¸ê¸° ë˜ëŠ” í† ë§ˆí† ì— ëŒ€í•œ ë³‘í•´ì¶© ì •ë³´ ë˜ëŠ” ë†ì•½/ë¹„ë£Œ ì •ë³´ê°€ ë¬¸ì„œì— ì—†ì„ ê²½ìš°, ì›¹ì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
        "ì›¹ì—ì„œ ê°€ì ¸ì˜¨ ìµœì‹  ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”. "
        "ì‚¬ìš© ì‹œ 'ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œê³µëœ ì •ë³´ì…ë‹ˆë‹¤.' ë¬¸êµ¬ê°€ ë°˜ë“œì‹œ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
)

# 4. Chroma ë²¡í„° DB ì²˜ë¦¬
def get_vectorstore(pdf_path, index_path, crop):
    if os.path.exists(index_path):
        return Chroma(persist_directory=index_path, embedding_function=embeddings)
    docs = load_docs_with_metadata(pdf_path, crop)
    split_docs = text_splitter.split_documents(docs)
    vs = Chroma.from_documents(split_docs, embeddings, persist_directory=index_path)
    vs.persist()
    return vs

# ê²½ë¡œ
strawberry_path = "data/ë”¸ê¸° ë³‘í•´ì¶© ë° ë¹„ë£Œ.pdf"
tomato_path = "data/í† ë§ˆí†  ë³‘í•´ì¶© ë° ë¹„ë£Œ.pdf"
strawberry_index_path = "chroma_index/strawberry"
tomato_index_path = "chroma_index/tomato"

strawberry_vectorstore = get_vectorstore(strawberry_path, strawberry_index_path, "ë”¸ê¸°")
tomato_vectorstore = get_vectorstore(tomato_path, tomato_index_path, "í† ë§ˆí† ")

# 5. í•„í„° ê¸°ë°˜ retriever tool ë˜í•‘
def make_filtered_tool(name, vectorstore, crop_name):
    retriever = vectorstore.as_retriever()

    def _filtered_search(query: str) -> str:
        filters = extract_filter_from_query(query)
        return retriever.invoke(query, filter=filters)

    return Tool(
        name=name,
        func=_filtered_search,
        description=(
            f"{crop_name}ì— ë°œìƒí•˜ëŠ” ë³‘í•´ì¶©ì„ ì§„ë‹¨í•˜ê³ , í•´ë‹¹ ë³‘í•´ì¶©ì— íš¨ê³¼ì ì¸ ë†ì•½ ì´ë¦„ê³¼ ì‚¬ìš© ì‹œê¸°ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. "
            "ë˜í•œ ìƒìœ¡ ë‹¨ê³„ì— ë”°ë¼ ì ì ˆí•œ ë¹„ë£Œ/í‡´ë¹„ ì •ë³´ë„ ì œê³µí•©ë‹ˆë‹¤."
        )
    )

strawberry_retriever_tool = make_filtered_tool("strawberry", strawberry_vectorstore, "ë”¸ê¸°")
tomato_retriever_tool = make_filtered_tool("tomato", tomato_vectorstore, "í† ë§ˆí† ")

tools = [strawberry_retriever_tool, tomato_retriever_tool, web_search_tool]

# í”„ë¡¬í”„íŠ¸ ì •ì˜
prompt = ChatPromptTemplate.from_messages([
    ("system", 
 "ë‹¹ì‹ ì€ ì‘ë¬¼ ë³‘í•´ì¶© ì§„ë‹¨, ë†ì•½ ë° ë¹„ë£Œ(í‡´ë¹„) ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•´ ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ê´€ë ¨ëœ í•­ëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš”."

"ì§ˆë¬¸ ë²”ì£¼:"

"ë³‘í•´ì¶©ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ê²½ìš°:"

"âœ… ë³‘í•´ì¶© ì´ë¦„"
"ğŸ§´ ì¶”ì²œ ë†ì•½"
"ğŸ’Š ë†ì•½ ì‚¬ìš© ë°©ë²•"
"ğŸ•“ ë†ì•½ ì‚¬ìš© ì‹œê¸°"
"ğŸ§° ë°©ì œ ë°©ë²•"

"ë†ì•½ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ê²½ìš°:"
"ğŸ§´ ì¶”ì²œ ë†ì•½"
"ğŸ’Š ë†ì•½ ì‚¬ìš© ë°©ë²•"
"ğŸ•“ ë†ì•½ ì‚¬ìš© ì‹œê¸°"

"ë¹„ë£Œë‚˜ í‡´ë¹„ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ê²½ìš°: í•„ìš”í•œ ì˜ì–‘ì†Œì™€ ë¹„ë£Œ ì‚¬ìš© ë°©ë²• ë° ì‹œê¸°, ìš©ëŸ‰ë§Œ ì¶œë ¥: ëª¨ë“  ì •ë³´ë¥¼ ì œê³µ"

"ğŸŒ¿ í•„ìš”í•œ ì˜ì–‘ì†Œ"
"ğŸ“† ë¹„ë£Œ ì‚¬ìš© ì‹œê¸°"
"ğŸ§ª ë¹„ë£Œ ì‚¬ìš© ë°©ë²•"
"âš–ï¸ ë¹„ë£Œ ì‚¬ìš© ìš©ëŸ‰"

"ë„êµ¬ ì‚¬ìš© ì§€ì¹¨:"

"ê´€ë ¨ ì •ë³´ëŠ” strawberry_retriever_tool ë˜ëŠ” tomato_retriever_toolì„ í†µí•´ ê²€ìƒ‰í•˜ì„¸ìš”."
"ì •ë³´ê°€ ë¶€ì¡±í•  ê²½ìš° web_search_toolë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
"ì›¹ ê²€ìƒ‰ íˆ´ì„ ì‚¬ìš©í–ˆë‹¤ë©´ ê²°ê³¼ í•˜ë‹¨ì— 'ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œê³µëœ ì •ë³´ì…ë‹ˆë‹¤.'ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."

"ì°¸ê³ :"

"ìƒì„¸ ì‚¬ìš©ë²•ì€ ë†ì•½/ë¹„ë£Œ ë¼ë²¨ ë˜ëŠ” ë†ì´Œì§„í¥ì²­ ìë£Œë¥¼ ì°¸ê³ í•˜ì„¸ìš”."

),

    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Agent ì‹¤í–‰ê¸° êµ¬ì„±
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)

# ì˜ˆì‹œ ì‹¤í–‰
response = agent_executor.invoke({
    "input": "ë”¸ê¸° ì¿ë¹›ê³°íŒ¡ì´ë³‘ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜"
})

print(response["output"].strip()) 


